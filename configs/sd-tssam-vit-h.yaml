train_dataset:
  dataset:
    name: paired-image-folders
    args:
      root_path_1: /home/bob/dataset/ISTD_Dataset/train/train_A
      root_path_2: /home/bob/dataset/ISTD_Dataset/train/train_B
      cache: none
      split_key: train
  wrapper:
    name: train
    args:
      inp_size: 1024
      augment: false
  batch_size: 2

val_dataset:
  dataset:
    name: paired-image-folders
    args:
      root_path_1: /home/bob/dataset/ISTD_Dataset/test/test_A
      root_path_2: /home/bob/dataset/ISTD_Dataset/test/test_B
      cache: none
      split_key: test
  wrapper:
    name: val
    args:
      inp_size: 1024
  batch_size: 1

test_dataset:
  dataset:
    name: paired-image-folders
    args:
      root_path_1: /home/bob/dataset/ISTD_Dataset/test/test_A
      root_path_2: /home/bob/dataset/ISTD_Dataset/test/test_B
      cache: none
      split_key: test
  wrapper:
    name: val
    args:
      inp_size: 1024
  batch_size: 1

eval_type: ber
sam_checkpoint: /root/autodl-tmp/model/sam_vit_h_4b8939.pth
data_norm:
  inp:
    sub:
    - 0.5
    div:
    - 0.5
  gt:
    sub:
    - 0.5
    div:
    - 0.5
  gt_rgb:
    sub:
    - 0.5
    div:
    - 0.5
model:
  name: sam
  args:
    inp_size: 1024
    loss: bbce
    encoder_mode:
      name: sam
      img_size: 1024
      mlp_ratio: 4
      patch_size: 16
      qkv_bias: true
      use_rel_pos: true
      window_size: 14
      out_chans: 256
      input_type: fft
      freq_nums: 0.25
      prompt_type: highpass
      prompt_embed_dim: 256
      tuning_stage: 1234
      handcrafted_tune: true
      embedding_tune: true
      adaptor: adaptor
      embed_dim: 1280
      depth: 32
      num_heads: 16
      global_attn_indexes:
      - 7
      - 15
      - 23
      - 31
      scale_factor: 5
      use_fft: true
      csa_block_indice: !!python/tuple [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]
      mrm_block_indice: !!python/tuple [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
optimizer:
  name: adamw
  args:
    lr: 0.0008
lr_min: 1.0e-7
epoch_max: 100

multi_step_lr:
  milestones:
  - 1
  gamma: 0.1
epoch_val: 1
epoch_save: 1

#resume: 60
#start_epoch: 60